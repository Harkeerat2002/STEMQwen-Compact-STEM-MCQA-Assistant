{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c555a54b",
   "metadata": {},
   "source": [
    "# Reasoning Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ed34a9",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc8896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import tqdm as tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5b9284",
   "metadata": {},
   "source": [
    "## Final Reasoning Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f29644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame()\n",
    "\n",
    "# Set the Columns Names\n",
    "columns = ['question', 'reasoning', 'answer', 'source']\n",
    "\n",
    "df_final = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c79711",
   "metadata": {},
   "source": [
    "## NuminaMath-CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f130493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading NuminaMath-CoT dataset...\")\n",
    "ds_math = load_dataset(\"AI-MO/NuminaMath-CoT\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Load the Train Set\n",
    "print(\"Converting train set to pandas DataFrame...\")\n",
    "train_df_math = ds_math[\"train\"].to_pandas()\n",
    "print(\"Train set converted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad37b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decrease the size of the dataset to 100k, but shufle it\n",
    "#train_df_math = train_df_math.sample(n=100000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "def extract_answer(solution, question):\n",
    "    \"\"\"\n",
    "    Extract the answer from the solution string.\n",
    "    1. Finds the first occurrence of \\boxed{...} (with or without $), even if it spans multiple lines and braces.\n",
    "    2. If not found, searches for 'Conclusion' and returns everything below it.\n",
    "    3. If not found, finds $\\blacksquare$ and returns the two lines above it.\n",
    "    4. If the answer is a single letter (A, B, C, D), extract the corresponding option from the question.\n",
    "    \"\"\"\n",
    "    # Improved boxed extraction to handle nested braces\n",
    "    match = re.search(r\"\\$?\\\\boxed\\{((?:[^{}]|\\{[^{}]*\\})*)\\}\\$?\", solution, re.DOTALL)\n",
    "    if match:\n",
    "        answer = match.group(1).strip()\n",
    "    else:\n",
    "        # If not found, look for 'Conclusion'\n",
    "        conclusion_match = re.search(r\"Conclusion[:\\-]?\\s*(.*)\", solution, re.IGNORECASE | re.DOTALL)\n",
    "        if conclusion_match:\n",
    "            answer = conclusion_match.group(1).strip()\n",
    "        else:\n",
    "            # If not found, look for $\\blacksquare$ and return two lines above\n",
    "            blacksquare_match = re.search(r\"\\$\\\\blacksquare\\$\", solution)\n",
    "            if blacksquare_match:\n",
    "                lines = solution[:blacksquare_match.start()].splitlines()\n",
    "                if len(lines) >= 2:\n",
    "                    answer = \"\\n\".join(lines[-2:]).strip()\n",
    "                elif lines:\n",
    "                    answer = lines[-1].strip()\n",
    "                else:\n",
    "                    answer = None\n",
    "            else:\n",
    "                answer = None\n",
    "\n",
    "    # If answer is a single letter (A, B, C, D), extract the corresponding option from the question\n",
    "    if answer and re.search(r\"[A-D]\", answer):\n",
    "        answer = re.sub(r\"[^A-D]\", \"\", answer).strip()\n",
    "        option_match = re.search(rf\"{answer}:\\s*(.*)\", question)\n",
    "        if option_match:\n",
    "            return f\"{answer}. {option_match.group(1).strip()}\"\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Iterate over the train set and append to the final DataFrame\n",
    "print(train_df_math.shape)\n",
    "filtered_df_math = pd.DataFrame(columns=columns)\n",
    "\n",
    "rows = []\n",
    "removed_rows = 0\n",
    "for index, row in tqdm.tqdm(train_df_math.iterrows(), total=len(train_df_math)):\n",
    "    answer = extract_answer(row['solution'], row['problem'])\n",
    "    if answer is None:\n",
    "        removed_rows += 1\n",
    "        continue\n",
    "    else:\n",
    "        question = row['problem']\n",
    "        reasoning = row['solution']\n",
    "        source = row['source']\n",
    "        rows.append({\n",
    "            'question': question,\n",
    "            'reasoning': reasoning,\n",
    "            'answer': answer,\n",
    "            'source': source\n",
    "        })\n",
    "\n",
    "filtered_df_math = pd.DataFrame(rows, columns=columns)\n",
    "    \n",
    "    \n",
    "print(f\"Removed {removed_rows} rows without valid answers.\")\n",
    "print(f\"Filtered DataFrame shape: {filtered_df_math.shape}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde7442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print 1st row each column\n",
    "print(\"First row of each column:\")\n",
    "for col in columns:\n",
    "    print(f\"{col}: {filtered_df_math[col].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04150b2f",
   "metadata": {},
   "source": [
    "## allenai/sciq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e750010",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading NuminaMath-CoT dataset...\")\n",
    "ds_sciq = load_dataset(\"allenai/sciq\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Load the Train Set\n",
    "print(\"Converting train set to pandas DataFrame...\")\n",
    "train_df_sciq = ds_sciq[\"train\"].to_pandas()\n",
    "print(\"Train set converted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e4ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_options(distractor1, distractor2, distractor3, answer):\n",
    "    \"\"\"\n",
    "    Shuffle and create a string of options in the format:\n",
    "    A: option1\n",
    "    B: option2\n",
    "    C: option3\n",
    "    D: option4\n",
    "    Also returns the correct option label (A/B/C/D) and the answer string.\n",
    "    \"\"\"\n",
    "    options = [distractor1, distractor2, distractor3, answer]\n",
    "    random.shuffle(options)\n",
    "    option_labels = ['A', 'B', 'C', 'D']\n",
    "    options_str_list = []\n",
    "    answer_label = None\n",
    "    for idx, opt in enumerate(options):\n",
    "        label = option_labels[idx]\n",
    "        options_str_list.append(f\"{label}: {opt}\")\n",
    "        if opt == answer:\n",
    "            answer_label = label\n",
    "    options_str = \"\\n\".join(options_str_list)\n",
    "    \n",
    "    answer = f\"{answer_label}: {answer}\"\n",
    "    return options_str, answer\n",
    "    \n",
    "filtered_df_sciq = pd.DataFrame(columns=columns)\n",
    "rows = []\n",
    "for index, row_sciq in tqdm.tqdm(train_df_sciq.iterrows(), total=len(train_df_sciq)):\n",
    "    distractor1 = row_sciq['distractor1']\n",
    "    distractor2 = row_sciq['distractor2']\n",
    "    distractor3 = row_sciq['distractor3']\n",
    "    answer = row_sciq['correct_answer']\n",
    "    question = row_sciq['question']\n",
    "    reasoning = row_sciq['support']\n",
    "    options = create_options(distractor1, distractor2, distractor3, answer)\n",
    "    \n",
    "    rows.append({\n",
    "        'question': question + \"\\n\" + options[0],\n",
    "        'reasoning': reasoning,\n",
    "        'answer': options[1],\n",
    "        'source': \"SciQ\"\n",
    "    })\n",
    "filtered_df_sciq = pd.DataFrame(rows, columns=columns)\n",
    "print(f\"Filtered SciQ DataFrame shape: {filtered_df_sciq.shape}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f61b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print 1st row each column\n",
    "print(\"First row of each column:\")\n",
    "for col in columns:\n",
    "    print(f\"{col}: {filtered_df_sciq[col].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d5a9c2",
   "metadata": {},
   "source": [
    "## deepmind/aqua_rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08a6bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading NuminaMath-CoT dataset...\")\n",
    "ds_rat = load_dataset(\"deepmind/aqua_rat\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Load the Train Set\n",
    "print(\"Converting train set to pandas DataFrame...\")\n",
    "train_df_rat = ds_rat[\"train\"].to_pandas()\n",
    "print(\"Train set converted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88a01a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_options_and_answer(options, answer):\n",
    "    \"\"\"\n",
    "    Options is as [\"A)21\",\"B)21.5\",\"C)22\",\"D)22.5\",\"E)23\"] and I want it as A: 21\\nB: 21.5\\nC: 22\\nD: 22.5\\nE: 23\n",
    "    Answer is as E and I want it as E: 23\n",
    "    \"\"\"\n",
    "    options_str_list = []\n",
    "    for option in options:\n",
    "        label, value = option.split(\")\", 1)\n",
    "        label = label.strip()\n",
    "        value = value.strip()\n",
    "        if answer == label:\n",
    "            answer = f\"{label}: {value}\"\n",
    "        options_str_list.append(f\"{label}: {value}\")\n",
    "    options_str = \"\\n\".join(options_str_list)\n",
    "    \n",
    "    return options_str, answer\n",
    "\n",
    "\n",
    "train_df_rat = train_df_rat.sample(n=20000, random_state=42).reset_index(drop=True)\n",
    "filtered_df_rat = pd.DataFrame(columns=columns)\n",
    "rows = []\n",
    "for index, row_rat in tqdm.tqdm(train_df_rat.iterrows(), total=len(train_df_rat)):\n",
    "    question = row_rat['question']\n",
    "    reasoning = row_rat['rationale']\n",
    "    options = row_rat['options']\n",
    "    answer = row_rat['correct']\n",
    "    options_str, answer = format_options_and_answer(options, answer)\n",
    "    \n",
    "    rows.append({\n",
    "        'question': question + \"\\n\" + options_str,\n",
    "        'reasoning': reasoning,\n",
    "        'answer': answer,\n",
    "        'source': \"AQUA-RAT\"\n",
    "    })\n",
    "filtered_df_rat = pd.DataFrame(rows, columns=columns)\n",
    "print(f\"Filtered AQUA-RAT DataFrame shape: {filtered_df_rat.shape}\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print 1st row each column\n",
    "print(\"First row of each column:\")\n",
    "for col in columns:\n",
    "    print(f\"{col}: {filtered_df_rat[col].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adabad6",
   "metadata": {},
   "source": [
    "## openlifescienceai/medmcqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bb7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading NuminaMath-CoT dataset...\")\n",
    "ds_med = load_dataset(\"openlifescienceai/medmcqa\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Load the Train Set\n",
    "print(\"Converting train set to pandas DataFrame...\")\n",
    "train_df_med = ds_med[\"train\"].to_pandas()\n",
    "print(\"Train set converted successfully.\")\n",
    "\n",
    "# Filter out the rows which has exp as null\n",
    "train_df_med = train_df_med[train_df_med['exp'].notnull()].reset_index(drop=True)\n",
    "\n",
    "# Filter out the choice_type to single\n",
    "train_df_med = train_df_med[train_df_med['choice_type'] == 'single'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eaf41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_med = train_df_med.sample(n=10000, random_state=42).reset_index(drop=True)\n",
    "filtered_df_med = pd.DataFrame(columns=columns)\n",
    "rows = []\n",
    "for index, row_med in tqdm.tqdm(train_df_med.iterrows(), total=len(train_df_med)):\n",
    "    option_a = row_med['opa']\n",
    "    option_b = row_med['opb']\n",
    "    option_c = row_med['opc']\n",
    "    option_d = row_med['opd']\n",
    "    answer = row_med['cop']\n",
    "    if answer == 0:\n",
    "        answer = \"A: \" + option_a\n",
    "    elif answer == 1:\n",
    "        answer = \"B: \" + option_b\n",
    "    elif answer == 2:\n",
    "        answer = \"C: \" + option_c\n",
    "    elif answer == 3:\n",
    "        answer = \"D: \" + option_d\n",
    "    question = row_med['question']\n",
    "    reasoning = row_med['exp']\n",
    "    options_str = f\"A: {option_a}\\nB: {option_b}\\nC: {option_c}\\nD: {option_d}\"\n",
    "    rows.append({\n",
    "        'question': question + \"\\n\" + options_str,\n",
    "        'reasoning': reasoning,\n",
    "        'answer': answer,\n",
    "        'source': \"MedMCQA\"\n",
    "    })\n",
    "filtered_df_med = pd.DataFrame(rows, columns=columns)\n",
    "print(f\"Filtered MedMCQA DataFrame shape: {filtered_df_med.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3630f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print 1st row each column\n",
    "print(\"First row of each column:\")\n",
    "for col in columns:\n",
    "    print(f\"{col}: {filtered_df_med[col].iloc[0]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83778452",
   "metadata": {},
   "source": [
    "## Making the Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([filtered_df_math, filtered_df_sciq, filtered_df_rat, filtered_df_med], ignore_index=True)\n",
    "# Shuffle the final DataFrame\n",
    "df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Final DataFrame shape: {df_final.shape}\")\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f4182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the final DataFrame into train and test sets\n",
    "train_size = int(0.95 * len(df_final))\n",
    "df_train = df_final[:train_size]\n",
    "df_test = df_final[train_size:]\n",
    "# Save the train and test sets to panquart files\n",
    "train_file = \"reasoning_dataset_train.parquet\"\n",
    "test_file = \"reasoning_dataset_test.parquet\"\n",
    "directory = \"datasets\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "train_path = os.path.join(directory, train_file)\n",
    "test_path = os.path.join(directory, test_file)\n",
    "df_train.to_parquet(train_path, index=False)\n",
    "df_test.to_parquet(test_path, index=False)\n",
    "print(f\"Train DataFrame saved to {train_path}\")\n",
    "print(f\"Test DataFrame saved to {test_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
